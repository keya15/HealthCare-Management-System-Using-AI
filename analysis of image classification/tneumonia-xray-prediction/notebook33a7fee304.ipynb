{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-26T06:31:58.370128Z","iopub.execute_input":"2023-08-26T06:31:58.371108Z","iopub.status.idle":"2023-08-26T06:32:13.542558Z","shell.execute_reply.started":"2023-08-26T06:31:58.371061Z","shell.execute_reply":"2023-08-26T06:32:13.541141Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = '../input/chest-xray-pneumonia/chest_xray/train/'\nval_path = '../input/chest-xray-pneumonia/chest_xray/val/'\ntest_path = '../input/chest-xray-pneumonia/chest_xray/test/'","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.544876Z","iopub.execute_input":"2023-08-26T06:32:13.545874Z","iopub.status.idle":"2023-08-26T06:32:13.555138Z","shell.execute_reply.started":"2023-08-26T06:32:13.545837Z","shell.execute_reply":"2023-08-26T06:32:13.553952Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# re-size all the images to a size VGG-16 expects.\nIMAGE_SIZE = [224, 224]\n\n# Set the batch size\nBATCH_SIZE = 32  # try reducing batch size or freeze more layers if your GPU runs out of memory\nNUM_EPOCHS = 5\nLEARNING_RATE = 0.0001\nNUM_CLASSES = 2 # We are aware of it.","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.559239Z","iopub.execute_input":"2023-08-26T06:32:13.560174Z","iopub.status.idle":"2023-08-26T06:32:13.573340Z","shell.execute_reply.started":"2023-08-26T06:32:13.560129Z","shell.execute_reply":"2023-08-26T06:32:13.572203Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nCLASSES = os.listdir(train_path)\nNUM_CLASSES = len(CLASSES)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.575231Z","iopub.execute_input":"2023-08-26T06:32:13.576149Z","iopub.status.idle":"2023-08-26T06:32:13.595613Z","shell.execute_reply.started":"2023-08-26T06:32:13.576104Z","shell.execute_reply":"2023-08-26T06:32:13.594804Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(NUM_CLASSES)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.598616Z","iopub.execute_input":"2023-08-26T06:32:13.599024Z","iopub.status.idle":"2023-08-26T06:32:13.604371Z","shell.execute_reply.started":"2023-08-26T06:32:13.598991Z","shell.execute_reply":"2023-08-26T06:32:13.603070Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Class --> {} \\n and the length is : {}\".format(CLASSES, NUM_CLASSES))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.606095Z","iopub.execute_input":"2023-08-26T06:32:13.606840Z","iopub.status.idle":"2023-08-26T06:32:13.616699Z","shell.execute_reply.started":"2023-08-26T06:32:13.606802Z","shell.execute_reply":"2023-08-26T06:32:13.615675Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Class --> ['PNEUMONIA', 'NORMAL'] \n and the length is : 2\n","output_type":"stream"}]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.618390Z","iopub.execute_input":"2023-08-26T06:32:13.619134Z","iopub.status.idle":"2023-08-26T06:32:13.626785Z","shell.execute_reply.started":"2023-08-26T06:32:13.619096Z","shell.execute_reply":"2023-08-26T06:32:13.625651Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagen.flow_from_directory(\n    directory = train_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:13.628454Z","iopub.execute_input":"2023-08-26T06:32:13.629167Z","iopub.status.idle":"2023-08-26T06:32:18.329830Z","shell.execute_reply.started":"2023-08-26T06:32:13.629130Z","shell.execute_reply":"2023-08-26T06:32:18.328803Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 5216 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:18.331613Z","iopub.execute_input":"2023-08-26T06:32:18.331994Z","iopub.status.idle":"2023-08-26T06:32:18.337583Z","shell.execute_reply.started":"2023-08-26T06:32:18.331960Z","shell.execute_reply":"2023-08-26T06:32:18.336063Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_set = test_datagen.flow_from_directory(\n    directory = test_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:18.339219Z","iopub.execute_input":"2023-08-26T06:32:18.339581Z","iopub.status.idle":"2023-08-26T06:32:18.499301Z","shell.execute_reply.started":"2023-08-26T06:32:18.339547Z","shell.execute_reply":"2023-08-26T06:32:18.498310Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 624 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the VGG 16 library as shown below and add preprocessing layer to the front of VGG\n# Here we will be using imagenet weights\n\nvgg = VGG16(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:18.500962Z","iopub.execute_input":"2023-08-26T06:32:18.501689Z","iopub.status.idle":"2023-08-26T06:32:25.470461Z","shell.execute_reply.started":"2023-08-26T06:32:18.501653Z","shell.execute_reply":"2023-08-26T06:32:25.469175Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:25.472387Z","iopub.execute_input":"2023-08-26T06:32:25.472859Z","iopub.status.idle":"2023-08-26T06:32:25.479462Z","shell.execute_reply.started":"2023-08-26T06:32:25.472819Z","shell.execute_reply":"2023-08-26T06:32:25.478358Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(vgg.output)\n\nprediction = Dense(NUM_CLASSES, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:25.481745Z","iopub.execute_input":"2023-08-26T06:32:25.482618Z","iopub.status.idle":"2023-08-26T06:32:25.515433Z","shell.execute_reply.started":"2023-08-26T06:32:25.482580Z","shell.execute_reply":"2023-08-26T06:32:25.514502Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:25.519182Z","iopub.execute_input":"2023-08-26T06:32:25.519485Z","iopub.status.idle":"2023-08-26T06:32:25.530154Z","shell.execute_reply.started":"2023-08-26T06:32:25.519458Z","shell.execute_reply":"2023-08-26T06:32:25.529053Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:25.531975Z","iopub.execute_input":"2023-08-26T06:32:25.533072Z","iopub.status.idle":"2023-08-26T06:32:25.577495Z","shell.execute_reply.started":"2023-08-26T06:32:25.533041Z","shell.execute_reply":"2023-08-26T06:32:25.576702Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 2)                 50178     \n                                                                 \n=================================================================\nTotal params: 14,764,866\nTrainable params: 50,178\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:32:25.578506Z","iopub.execute_input":"2023-08-26T06:32:25.578847Z","iopub.status.idle":"2023-08-26T06:32:25.614312Z","shell.execute_reply.started":"2023-08-26T06:32:25.578815Z","shell.execute_reply":"2023-08-26T06:32:25.613325Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# callbacks\nimport tensorflow as tf\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"model.h5\", save_best_only=True)\nreduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=10)\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./pneumonia_clf_vgg16_logs\")\n\ncallbacks = [checkpoint_callback, reduce_lr_callback, early_stopping_callback,  tensorboard_callback ]","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:34:59.214273Z","iopub.execute_input":"2023-08-26T06:34:59.215382Z","iopub.status.idle":"2023-08-26T06:34:59.933826Z","shell.execute_reply.started":"2023-08-26T06:34:59.215282Z","shell.execute_reply":"2023-08-26T06:34:59.932731Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  training_set,\n  validation_data=test_set,\n  epochs=5,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set),\n    callbacks = callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:35:16.266131Z","iopub.execute_input":"2023-08-26T06:35:16.267115Z","iopub.status.idle":"2023-08-26T06:47:41.050045Z","shell.execute_reply.started":"2023-08-26T06:35:16.267063Z","shell.execute_reply":"2023-08-26T06:47:41.048975Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/5\n163/163 [==============================] - 176s 1s/step - loss: 0.1467 - accuracy: 0.9425 - val_loss: 0.3554 - val_accuracy: 0.8766 - lr: 0.0010\nEpoch 2/5\n163/163 [==============================] - 133s 817ms/step - loss: 0.1614 - accuracy: 0.9417 - val_loss: 0.3958 - val_accuracy: 0.8878 - lr: 0.0010\nEpoch 3/5\n163/163 [==============================] - 133s 816ms/step - loss: 0.1009 - accuracy: 0.9617 - val_loss: 0.3467 - val_accuracy: 0.9022 - lr: 0.0010\nEpoch 4/5\n163/163 [==============================] - 133s 819ms/step - loss: 0.0877 - accuracy: 0.9674 - val_loss: 0.3971 - val_accuracy: 0.9071 - lr: 0.0010\nEpoch 5/5\n163/163 [==============================] - 134s 819ms/step - loss: 0.0807 - accuracy: 0.9701 - val_loss: 0.2645 - val_accuracy: 0.9199 - lr: 0.0010\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:47:55.199252Z","iopub.execute_input":"2023-08-26T06:47:55.199646Z","iopub.status.idle":"2023-08-26T06:48:05.781610Z","shell.execute_reply.started":"2023-08-26T06:47:55.199615Z","shell.execute_reply":"2023-08-26T06:48:05.780499Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"20/20 [==============================] - 6s 318ms/step - loss: 0.2645 - accuracy: 0.9199\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[0.26449674367904663, 0.9198718070983887]"},"metadata":{}}]},{"cell_type":"code","source":"model.save( \"pneumonia_clf_vgg16.h5\" )","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:48:11.774265Z","iopub.execute_input":"2023-08-26T06:48:11.774690Z","iopub.status.idle":"2023-08-26T06:48:11.888779Z","shell.execute_reply.started":"2023-08-26T06:48:11.774656Z","shell.execute_reply":"2023-08-26T06:48:11.887743Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nloaded = tf.keras.models.load_model(\"pneumonia_clf_vgg16.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:48:16.922378Z","iopub.execute_input":"2023-08-26T06:48:16.922775Z","iopub.status.idle":"2023-08-26T06:48:17.243656Z","shell.execute_reply.started":"2023-08-26T06:48:16.922745Z","shell.execute_reply":"2023-08-26T06:48:17.242572Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"loaded == model","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:48:19.731355Z","iopub.execute_input":"2023-08-26T06:48:19.732054Z","iopub.status.idle":"2023-08-26T06:48:19.738231Z","shell.execute_reply.started":"2023-08-26T06:48:19.732017Z","shell.execute_reply":"2023-08-26T06:48:19.737233Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"loaded.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:48:22.738987Z","iopub.execute_input":"2023-08-26T06:48:22.740185Z","iopub.status.idle":"2023-08-26T06:48:29.709421Z","shell.execute_reply.started":"2023-08-26T06:48:22.740141Z","shell.execute_reply":"2023-08-26T06:48:29.708243Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"20/20 [==============================] - 7s 315ms/step - loss: 0.2645 - accuracy: 0.9199\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[0.26449674367904663, 0.9198718070983887]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"model.h5\", save_best_only=True)\nreduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=10)\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:48:36.096698Z","iopub.execute_input":"2023-08-26T06:48:36.097129Z","iopub.status.idle":"2023-08-26T06:48:36.103464Z","shell.execute_reply.started":"2023-08-26T06:48:36.097096Z","shell.execute_reply":"2023-08-26T06:48:36.102493Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}